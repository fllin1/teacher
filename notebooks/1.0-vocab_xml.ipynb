{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_list (value: Any) -> list:\n",
    "    if type(value) is not list:\n",
    "        value = [value]\n",
    "    return value\n",
    "\n",
    "def save_json(vocab, path):\n",
    "    \"\"\"\n",
    "    Save progress to a JSON file.\n",
    "\n",
    "    Args:\n",
    "        vocab (dict): The vocabulary dictionary to save.\n",
    "        path (Path): The path to the JSON file.\n",
    "    \"\"\"\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(vocab, f, indent=4, ensure_ascii=False)\n",
    "    print(f\"Progress saved to {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cards(root: etree.Element) -> list:\n",
    "    cards = []\n",
    "    for card in root.find('cards').findall('card'):    \n",
    "        \n",
    "        entry = card.find('entry')\n",
    "        try:\n",
    "            definition = entry.find('defn').text\n",
    "            category = card.find('catassign').attrib['category'] \n",
    "            if \"Cours1\" in category or \"Cours2\" in category or \"Cours3\" in category:\n",
    "                continue\n",
    "        except AttributeError:\n",
    "            definition = None\n",
    "            category = None\n",
    "        \n",
    "        headword = entry.find('headword').text\n",
    "        pronunciation = entry.find('pron').text\n",
    "        \n",
    "        score_info = card.find('scoreinfo')\n",
    "        \n",
    "        card_details = {\n",
    "            'character': headword,\n",
    "            'pronunciation': pronunciation,\n",
    "            'traduction': definition,\n",
    "            'category': category,\n",
    "            'score': score_info.attrib.get('score') if score_info is not None else None,\n",
    "            'difficulty': score_info.attrib.get('difficulty') if score_info is not None else None,\n",
    "            'correct': score_info.attrib.get('correct') if score_info is not None else None,\n",
    "            'incorrect': score_info.attrib.get('incorrect') if score_info is not None else None,\n",
    "            'reviewed': score_info.attrib.get('reviewed') if score_info is not None else None,\n",
    "        }\n",
    "        \n",
    "        cards.append(card_details)\n",
    "\n",
    "    return cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_cards_by_categories(root, keywords: Union[list, str]) -> etree.Element:\n",
    "    \"\"\"\n",
    "    Remove all cards where the category contains any keyword from a list.\n",
    "\n",
    "    Args:\n",
    "        root (xml.etree.ElementTree.Element): The root of the XML tree.\n",
    "        keywords (Union[list, str]): A list of keywords to match against the category.\n",
    "\n",
    "    Returns:\n",
    "        xml.etree.ElementTree.Element: The modified root element.\n",
    "    \"\"\"\n",
    "    keywords = convert_to_list(keywords)\n",
    "    cards = root.find('cards')  # Locate the <cards> section\n",
    "    for card in list(cards):  # Iterate over a copy of the cards to avoid runtime issues\n",
    "        catassign = card.find('catassign')  # Locate the <catassign> element\n",
    "        if catassign is not None:  # Ensure <catassign> exists\n",
    "            category = catassign.attrib.get('category', '')  # Default to an empty string if 'category' is missing\n",
    "            if any(keyword.lower() in category.lower() for keyword in keywords):  # Match any keyword\n",
    "                cards.remove(card)\n",
    "    return root\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_chinese_definition(definition: str) -> Dict[str, List[Dict[str, List[str]]]]:\n",
    "    \"\"\"\n",
    "    Parses a Chinese word definition into structured categories, definitions, and examples.\n",
    "    \n",
    "    Args:\n",
    "        definition (str): The raw definition text.\n",
    "    \n",
    "    Returns:\n",
    "        Dict[str, List[Dict[str, List[str]]]]: A dictionary where each key is a part of speech,\n",
    "        and each value is a list of definitions with their examples.\n",
    "    \"\"\"\n",
    "    parts_of_speech = [\n",
    "        'adjective',\n",
    "        'adverb',\n",
    "        'affix',\n",
    "        'auxiliary',\n",
    "        'idiom',\n",
    "        'noun',\n",
    "        'preposition',\n",
    "        'pronoun',\n",
    "        'surname',\n",
    "        'verb'\n",
    "    ]\n",
    "\n",
    "    pos_pattern = r'\\b(' + '|'.join(parts_of_speech) + r')\\b'\n",
    "    matches = list(re.finditer(pos_pattern, definition))\n",
    "    if not matches:\n",
    "        matches = [0]\n",
    "\n",
    "    parsed_data = {}\n",
    "    positions = [match.start() for match in matches] + [len(definition)]\n",
    "    parts = [match.group(1) for match in matches]\n",
    "\n",
    "    for idx, pos in enumerate(positions[:-1]):\n",
    "        current_pos = parts[idx]\n",
    "        start_idx = pos\n",
    "        end_idx = positions[idx+1]\n",
    "        text = definition[start_idx:end_idx].strip()\n",
    "        text = re.sub(r'^\\b' + re.escape(current_pos) + r'\\b', '', text).strip()\n",
    "        definitions = split_definitions(text)\n",
    "        parsed_data[current_pos] = definitions\n",
    "\n",
    "    return parsed_data\n",
    "\n",
    "def split_definitions(text: str) -> List[Dict[str, List[str]]]:\n",
    "    \"\"\"\n",
    "    Splits the text into individual definitions and their examples.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The text containing definitions and examples.\n",
    "    \n",
    "    Returns:\n",
    "        List[Dict[str, List[str]]]: A list of dictionaries with 'definition' and 'examples'.\n",
    "    \"\"\"\n",
    "    definitions = []\n",
    "    # Séparer les définitions numérotées ou les différentes entrées\n",
    "    def_splits = re.split(r'(?=\\d+\\s)', text)\n",
    "    for def_text in def_splits:\n",
    "        def_text = def_text.strip()\n",
    "        if not def_text:\n",
    "            continue\n",
    "        # Extraire le numéro de définition s'il existe\n",
    "        match = re.match(r'^(\\d+)\\s', def_text)\n",
    "        if match:\n",
    "            def_number = match.group(1)\n",
    "            def_text = def_text[len(def_number):].strip()\n",
    "        else:\n",
    "            def_number = None\n",
    "        # Séparer la définition des exemples\n",
    "        example_splits = re.split(r'(?<=\\.)\\s+', def_text)\n",
    "        definition = example_splits[0]\n",
    "        examples = example_splits[1:] if len(example_splits) > 1 else []\n",
    "        # Nettoyer les exemples pour éliminer les espaces inutiles\n",
    "        examples = [ex.strip() for ex in examples if ex.strip()]\n",
    "        definitions.append({\n",
    "            'definition': definition,\n",
    "            'examples': examples\n",
    "        })\n",
    "    return definitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from typing import Any, Dict, List, Union\n",
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "\n",
    "class Card:\n",
    "    \"\"\"\n",
    "    Represents a single vocabulary card with Chinese characters and related information.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        character: str,\n",
    "        pronunciation: str,\n",
    "        traduction: str = None,\n",
    "        category: str = None,\n",
    "        score: str = None,\n",
    "        difficulty: str = None,\n",
    "        correct: str = None,\n",
    "        incorrect: str = None,\n",
    "        reviewed: str = None,\n",
    "    ):\n",
    "        self.character = character\n",
    "        self.pronunciation = pronunciation\n",
    "        self.traduction = traduction\n",
    "        self.category = category\n",
    "        self.score = score\n",
    "        self.difficulty = difficulty\n",
    "        self.correct = correct\n",
    "        self.incorrect = incorrect\n",
    "        self.reviewed = reviewed\n",
    "\n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Converts the card's data to a dictionary.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, Any]: The card's data as a dictionary.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'character': self.character,\n",
    "            'pronunciation': self.pronunciation,\n",
    "            'traduction': self.traduction,\n",
    "            'category': self.category,\n",
    "            'score': self.score,\n",
    "            'difficulty': self.difficulty,\n",
    "            'correct': self.correct,\n",
    "            'incorrect': self.incorrect,\n",
    "            'reviewed': self.reviewed,\n",
    "        }\n",
    "\n",
    "\n",
    "class CardManager:\n",
    "    \"\"\"\n",
    "    Manages a collection of Card objects and provides methods to load, filter, and save them.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.cards: List[Card] = []\n",
    "\n",
    "    def load_cards_from_xml(self, xml_path: str):\n",
    "        \"\"\"\n",
    "        Loads cards from an XML file.\n",
    "\n",
    "        Args:\n",
    "            xml_path (str): Path to the XML file containing the cards.\n",
    "        \"\"\"\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        for card_elem in root.find('cards').findall('card'):\n",
    "            entry = card_elem.find('entry')\n",
    "\n",
    "            catassign = card_elem.find('catassign')\n",
    "            category = catassign.attrib['category'] if catassign is not None else None\n",
    "            score_info = card_elem.find('scoreinfo')\n",
    "\n",
    "            card = Card(\n",
    "                character=entry.find('headword').text,\n",
    "                pronunciation=entry.find('pron').text,\n",
    "                traduction=entry.find('defn'),\n",
    "                category=category,\n",
    "                score=score_info.attrib.get('score') if score_info is not None else None,\n",
    "                difficulty=score_info.attrib.get('difficulty') if score_info is not None else None,\n",
    "                correct=score_info.attrib.get('correct') if score_info is not None else None,\n",
    "                incorrect=score_info.attrib.get('incorrect') if score_info is not None else None,\n",
    "                reviewed=score_info.attrib.get('reviewed') if score_info is not None else None,\n",
    "            )\n",
    "\n",
    "            self.cards.append(card)\n",
    "            print(f\"Loaded card: {card.traduction}\")\n",
    "\n",
    "    def remove_cards_by_categories(self, keywords: Union[List[str], str]):\n",
    "        \"\"\"\n",
    "        Removes cards where the category contains any of the specified keywords.\n",
    "\n",
    "        Args:\n",
    "            keywords (Union[List[str], str]): A keyword or list of keywords to match against the category.\n",
    "        \"\"\"\n",
    "        keywords = self._convert_to_list(keywords)\n",
    "        keywords = [k.lower() for k in keywords]\n",
    "\n",
    "        filtered_cards = []\n",
    "        for card in self.cards:\n",
    "            if card.category:\n",
    "                category_lower = card.category.lower()\n",
    "                if any(keyword in category_lower for keyword in keywords):\n",
    "                    continue  # Skip cards matching the keywords\n",
    "            filtered_cards.append(card)\n",
    "\n",
    "        self.cards = filtered_cards\n",
    "\n",
    "    def get_cards_data(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Retrieves the list of cards as dictionaries.\n",
    "\n",
    "        Returns:\n",
    "            List[Dict[str, Any]]: The list of card data.\n",
    "        \"\"\"\n",
    "        return [card.to_dict() for card in self.cards]\n",
    "\n",
    "    @staticmethod\n",
    "    def _convert_to_list(value: Any) -> List[Any]:\n",
    "        \"\"\"\n",
    "        Converts the input value to a list if it is not already a list.\n",
    "\n",
    "        Args:\n",
    "            value (Any): The input value, which can be of any type.\n",
    "\n",
    "        Returns:\n",
    "            List[Any]: The value converted to a list.\n",
    "        \"\"\"\n",
    "        if not isinstance(value, list):\n",
    "            value = [value]\n",
    "        return value\n",
    "\n",
    "\n",
    "class DefinitionParser:\n",
    "    \"\"\"\n",
    "    Parses Chinese word definitions into structured categories, definitions, and examples.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_definition(definition: str) -> Union[Dict[str, List[Dict[str, List[str]]]], str]:\n",
    "        \"\"\"\n",
    "        Parses a Chinese word definition into structured categories, definitions, and examples.\n",
    "\n",
    "        Args:\n",
    "            definition (str): The raw definition text.\n",
    "\n",
    "        Returns:\n",
    "            Union[Dict[str, List[Dict[str, List[str]]]], str]: A dictionary where each key is a part of speech,\n",
    "            and each value is a list of definitions with their examples, or the original definition if parsing fails.\n",
    "        \"\"\"\n",
    "        parts_of_speech = [\n",
    "            'adjective',\n",
    "            'adverb',\n",
    "            'affix',\n",
    "            'auxiliary',\n",
    "            'idiom',\n",
    "            'noun',\n",
    "            'preposition',\n",
    "            'pronoun',\n",
    "            'surname',\n",
    "            'verb',\n",
    "        ]\n",
    "\n",
    "        pos_pattern = r'\\b(' + '|'.join(parts_of_speech) + r')\\b'\n",
    "        matches = list(re.finditer(pos_pattern, definition, re.IGNORECASE))\n",
    "\n",
    "        if not matches:\n",
    "            return definition  # Return the whole definition if no parts of speech are found\n",
    "\n",
    "        parsed_data = {}\n",
    "\n",
    "        positions = [match.start() for match in matches] + [len(definition)]\n",
    "        parts = [match.group(1).lower() for match in matches]\n",
    "\n",
    "        for idx, pos in enumerate(positions[:-1]):\n",
    "            current_pos = parts[idx]\n",
    "            start_idx = pos\n",
    "            end_idx = positions[idx + 1]\n",
    "            text = definition[start_idx:end_idx].strip()\n",
    "            # Remove the part of speech from the beginning\n",
    "            text = re.sub(r'^\\b' + re.escape(current_pos) + r'\\b', '', text, flags=re.IGNORECASE).strip()\n",
    "            definitions = DefinitionParser._split_definitions(text)\n",
    "            parsed_data[current_pos] = definitions\n",
    "\n",
    "        return parsed_data\n",
    "\n",
    "    @staticmethod\n",
    "    def _split_definitions(text: str) -> List[Dict[str, List[str]]]:\n",
    "        \"\"\"\n",
    "        Splits the text into individual definitions and their examples.\n",
    "\n",
    "        Args:\n",
    "            text (str): The text containing definitions and examples.\n",
    "\n",
    "        Returns:\n",
    "            List[Dict[str, List[str]]]: A list of dictionaries with 'definition' and 'examples'.\n",
    "        \"\"\"\n",
    "        definitions = []\n",
    "        # Split numbered definitions or different entries\n",
    "        def_splits = re.split(r'(?=\\d+\\s)', text)\n",
    "        for def_text in def_splits:\n",
    "            def_text = def_text.strip()\n",
    "            if not def_text:\n",
    "                continue\n",
    "            # Extract the definition number if it exists\n",
    "            match = re.match(r'^(\\d+)\\s', def_text)\n",
    "            if match:\n",
    "                def_number = match.group(1)\n",
    "                def_text = def_text[len(def_number):].strip()\n",
    "            else:\n",
    "                def_number = None\n",
    "            # Split the definition and examples\n",
    "            example_splits = re.split(r'(?<=\\.)\\s+', def_text)\n",
    "            definition = example_splits[0]\n",
    "            examples = example_splits[1:] if len(example_splits) > 1 else []\n",
    "            # Clean up the examples\n",
    "            examples = [ex.strip() for ex in examples if ex.strip()]\n",
    "            definitions.append({\n",
    "                'definition': definition,\n",
    "                'examples': examples,\n",
    "            })\n",
    "        return definitions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = etree.parse('../data/raw/flash-2411112247.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "remove_categories = ['Cours1 ', 'Cours2 ', 'Cours3 ', 'Question Answer Voca']\n",
    "card_details = remove_cards_by_categories(root, remove_categories)\n",
    "\n",
    "card_details = get_cards(card_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(cards, '../data/processed/chinese_cards.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
